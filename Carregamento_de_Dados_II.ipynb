{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Carregamento de Dados II.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicpb/treinando-rn-dp-pytorch-alura/blob/main/Carregamento_de_Dados_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDM84H0wO5I_"
      },
      "source": [
        "# Carregamento de Dados\n",
        "\n",
        "Objetivos dessa aula:\n",
        "* Carregar um dataset customizado\n",
        "* Implementar o fluxo de treinamento **e validação** completo de uma rede\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg_W2-tDlpz3"
      },
      "source": [
        "## Hiperparâmetros\n",
        "\n",
        "Vamos manter a organização do último script :)\n",
        "\n",
        "* imports de pacotes\n",
        "* configuração de hiperparâmetros\n",
        "* definição do hardware padrão utilizado\n",
        "\n",
        "E bora de GPU de novo! \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfisIdsWlioB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb7dd1e-2ac5-4a72-c085-017177b512cc"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Configurando hiperparâmetros.\n",
        "args = {\n",
        "    'epoch_num': 200,     # Número de épocas.\n",
        "    'lr': 5e-5,           # Taxa de aprendizado.\n",
        "    'weight_decay': 5e-4, # Penalidade L2 (Regularização).\n",
        "    'num_workers': 3,     # Número de threads do dataloader.\n",
        "    'batch_size': 20,     # Tamanho do batch.\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyXDulgH77_s"
      },
      "source": [
        "## Dataset \n",
        "\n",
        "Dataset de aplicativos para aluguel de bicicletas (*Bike Sharing Dataset*). <br>\n",
        "* Dadas algumas informações como velocidade do vento, estação do ano, etc., quantas bicicletas serão alugadas na próxima hora?\n",
        "\n",
        "Esse é um problema de **Regressão**, onde precisamos estimar uma variável dependente em um espaço contínuo (alugueis de bikes) a partir de um conjunto de variáveis independentes (as condições no momento)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ydTqRvqH-1-"
      },
      "source": [
        "### Baixando o dataset\n",
        "\n",
        "Fonte: https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecgKLh2aKYH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ad89af-2281-4b28-8eb2-26ac56734292"
      },
      "source": [
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
        "! unzip Bike-Sharing-Dataset.zip  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-19 00:49:07--  https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 279992 (273K) [application/x-httpd-php]\n",
            "Saving to: ‘Bike-Sharing-Dataset.zip’\n",
            "\n",
            "Bike-Sharing-Datase 100%[===================>] 273.43K   982KB/s    in 0.3s    \n",
            "\n",
            "2021-05-19 00:49:07 (982 KB/s) - ‘Bike-Sharing-Dataset.zip’ saved [279992/279992]\n",
            "\n",
            "Archive:  Bike-Sharing-Dataset.zip\n",
            "  inflating: Readme.txt              \n",
            "  inflating: day.csv                 \n",
            "  inflating: hour.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjsCxBQJsTce"
      },
      "source": [
        "### Visualizando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUkvnM8SKlY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "9cf30bc7-b334-4860-ebf2-52f403889d45"
      },
      "source": [
        "df = pd.read_csv('hour.csv')\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "0        1  2011-01-01       1   0  ...        0.0       3          13   16\n",
              "1        2  2011-01-01       1   0  ...        0.0       8          32   40\n",
              "2        3  2011-01-01       1   0  ...        0.0       5          27   32\n",
              "3        4  2011-01-01       1   0  ...        0.0       3          10   13\n",
              "4        5  2011-01-01       1   0  ...        0.0       0           1    1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcvrTUl2OLmL"
      },
      "source": [
        "### Tratamento de dados\n",
        "\n",
        "**Variáveis Categóricas** <br>\n",
        "Como descrito na página do dataset, apenas as variáveis numéricas estão normalizadas. No caso das categóricas (como dia da semana e estação do ano), cada elemento contém o índice da categoria.\n",
        "\n",
        "Existem várias formas de lidar com variáveis categóricas em uma regressão, mas para não desviar o foco da nossa aula manteremos os valores originais das variáveis categóricas.\n",
        "\n",
        "**Separação em treino e teste**<br>\n",
        "\n",
        "Para treinar e validar o nosso modelo, precisamos de dois conjuntos de dados (treino e teste). Para isso, utilizaremos a função ```torch.randperm``` para amostrar aleatoriamente um percentual dos dados, separando-os para validação.\n",
        "\n",
        "Documentação: https://pytorch.org/docs/stable/torch.html#torch.randperm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnjCdm1bMqhG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "daa1ea3d-bef5-4435-c640-23c6177c3ebe"
      },
      "source": [
        "# Train/Test split\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(df)).tolist()\n",
        "\n",
        "train_size = int(0.8*len(df))\n",
        "df_train = df.iloc[indices[:train_size]]\n",
        "df_test  = df.iloc[indices[train_size:]]\n",
        "\n",
        "print(len(df_train), len(df_test))\n",
        "display(df_test.head())\n",
        "\n",
        "df_train.to_csv('bike_train.csv',index=False)\n",
        "df_test.to_csv('bike_test.csv',index=False)\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13903 3476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12663</th>\n",
              "      <td>12664</td>\n",
              "      <td>2012-06-16</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.6212</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>123</td>\n",
              "      <td>229</td>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1801</th>\n",
              "      <td>1802</td>\n",
              "      <td>2011-03-20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.3939</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.3582</td>\n",
              "      <td>58</td>\n",
              "      <td>98</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16567</th>\n",
              "      <td>16568</td>\n",
              "      <td>2012-11-28</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.2239</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8817</th>\n",
              "      <td>8818</td>\n",
              "      <td>2012-01-08</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1045</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>2609</td>\n",
              "      <td>2011-04-23</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.5455</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.3582</td>\n",
              "      <td>182</td>\n",
              "      <td>209</td>\n",
              "      <td>391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "12663    12664  2012-06-16       2   1  ...     0.1940     123         229  352\n",
              "1801      1802  2011-03-20       1   0  ...     0.3582      58          98  156\n",
              "16567    16568  2012-11-28       4   1  ...     0.2239       0          12   12\n",
              "8817      8818  2012-01-08       1   1  ...     0.1045       0           2    2\n",
              "2608      2609  2011-04-23       2   0  ...     0.3582     182         209  391\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Bike-Sharing-Dataset.zip  bike_train.csv  hour.csv    sample_data\n",
            "bike_test.csv\t\t  day.csv\t  Readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daUL9nMxICW0"
      },
      "source": [
        "### Classe Dataset\n",
        "\n",
        "O pacote ```torch.util.data``` possui a classe abstrata ```Dataset```. Ela permite que você implemente o seu próprio dataset reescrevendo os métodos:\n",
        "\n",
        "* ```__init__(self)```: Define a lista de amostras do seu dataset\n",
        "* ```__getitem__(self, idx)```: Carrega uma amostra, aplica as devidas transformações e retorna uma **tupla ```(dado, rótulo)```**.\n",
        "* ```__len__(self)```: Retorna a quantidade de amostras do dataset\n",
        "\n",
        "Tutorial completo do PyTorch: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaLPZteS9fkW"
      },
      "source": [
        "class Bicicletinha(Dataset):\n",
        "  def __init__(self, csv_path, scaler_feat=None, scaler_label=None):\n",
        "  \n",
        "    self.dados = pd.read_csv(csv_path).to_numpy()\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    sample = self.dados[idx][2:14]\n",
        "    label  = self.dados[idx][-1:]\n",
        "    \n",
        "    # converte para tensor\n",
        "    sample = torch.from_numpy(sample.astype(np.float32))\n",
        "    label  = torch.from_numpy(label.astype(np.float32))\n",
        "    \n",
        "    return sample, label\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.dados)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd4yl7sbQQGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357ef4ad-33f4-44b4-a304-902d4c76e7b8"
      },
      "source": [
        "dataset = Bicicletinha('bike_train.csv')\n",
        "dado, rotulo = dataset[0]\n",
        "print(rotulo)\n",
        "print(dado)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([373.])\n",
            "tensor([ 4.0000,  1.0000, 11.0000, 19.0000,  0.0000,  4.0000,  1.0000,  1.0000,\n",
            "         0.3800,  0.3939,  0.2700,  0.3582])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwS8q0l0v8cP"
      },
      "source": [
        "### Construindo conjuntos de treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8nAUzhxUlrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0407e4-0580-457e-94bd-a9d310edcb72"
      },
      "source": [
        "train_set = Bicicletinha('bike_train.csv')\n",
        "test_set  = Bicicletinha('bike_test.csv')\n",
        "\n",
        "print('Tamanho do treino: ' + str(len(train_set)) + ' amostras')\n",
        "print('Tamanho do teste: ' + str(len(test_set)) + ' amostras')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho do treino: 13903 amostras\n",
            "Tamanho do teste: 3476 amostras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZq6iuq6lQ9N"
      },
      "source": [
        "## Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuETOc64MynK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a161fc-55ae-40ca-9417-17764c915bc5"
      },
      "source": [
        "# Criando dataloader\n",
        "train_loader = DataLoader(train_set,\n",
        "                          args['batch_size'],\n",
        "                          num_workers=args['num_workers'],\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         args['batch_size'],\n",
        "                         num_workers=args['num_workers'],\n",
        "                         shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_wBx0Uesrgu"
      },
      "source": [
        "O objeto retornado é um **iterador**, podendo ser utilizado para iterar em loops mas não suportando indexação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zw1aAcsVCyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92a0de6-d857-4e92-9f54-66f9a869ce34"
      },
      "source": [
        "for batch in test_loader:\n",
        "  \n",
        "  dado, rotulo = batch\n",
        "  print('## Dimensionalidade do batch ##')\n",
        "  print(dado.size(), rotulo.size())\n",
        "  \n",
        "  break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "## Dimensionalidade do batch ##\n",
            "torch.Size([20, 12]) torch.Size([20, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPCE1MC8yf02"
      },
      "source": [
        "## Implementando o MLP\n",
        "\n",
        "Essa parte aqui você já tira de letra! Minha sugestão é construir um modelo com:\n",
        "\n",
        "* **Duas camadas escondidas**. Lembre-se de alternar as camadas com ativações não-lineares. \n",
        "* Uma camada de saída (com qual ativação?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-9spUHCUzBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4133e962-5e0b-4c7d-c3ae-f294c8b076f2"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, out_size):\n",
        "    super(MLP, self).__init__()\n",
        "    \n",
        "    self.features = nn.Sequential(\n",
        "          nn.Linear(input_size, hidden_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size, hidden_size),\n",
        "          nn.ReLU(),\n",
        "    )\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, out_size),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    \n",
        "    hidden = self.features(X)\n",
        "    output = self.classifier(hidden)\n",
        "    \n",
        "    return output\n",
        "\n",
        "input_size  = train_set[0][0].size(0)\n",
        "hidden_size = 128\n",
        "out_size    = 1\n",
        "\n",
        "net = MLP(input_size, hidden_size, out_size).to(args['device'])\n",
        "print(net)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (features): Sequential(\n",
            "    (0): Linear(in_features=12, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb7zTsWV1cyQ"
      },
      "source": [
        "## Definindo loss e otimizador\n",
        "\n",
        "Se lembra quais as funções de perda adequadas para um problema de regressão?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx4MecnX1e2E"
      },
      "source": [
        "criterion = nn.L1Loss().to(args['device'])\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ujnT7rl0bjg"
      },
      "source": [
        "# Fluxo de Treinamento & Validação\n",
        "\n",
        "## Treinamento\n",
        "\n",
        "Relembrando o passo a passo do fluxo de treinamento:\n",
        "* Iterar nas épocas\n",
        "* Iterar nos batches\n",
        "* Cast dos dados no dispositivo de hardware\n",
        "* Forward na rede e cálculo da loss\n",
        "* Cálculo do gradiente e atualização dos pesos\n",
        "\n",
        "Esse conjunto de passos é responsável pelo processo iterativo de otimização de uma rede. **A validação** por outro lado, é apenas a aplicação da rede em dados nunca antes visto para estimar a qualidade do modelo no mundo real.\n",
        "\n",
        "## Validação\n",
        "\n",
        "Para essa etapa, o PyTorch oferece dois artifícios:\n",
        "* ```model.eval()```: Impacta no *forward* da rede, informando as camadas caso seu comportamento mude entre fluxos (ex: dropout).\n",
        "* ```with torch.no_grad()```: Gerenciador de contexto que desabilita o cálculo e armazenamento de gradientes (economia de tempo e memória). Todo o código de validação deve ser executado dentro desse contexto.\n",
        "\n",
        "Exemplo de código para validação\n",
        "\n",
        "```python\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for batch in test_loader:\n",
        "      # Código de validação\n",
        "```\n",
        "\n",
        "Existe o equivalente ao ```model.eval()``` para explicitar que a sua rede deve estar em modo de treino, é o ```model.train()```. Apesar de ser o padrão dos modelos, é boa prática definir também o modo de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUwXgLyM4V2T"
      },
      "source": [
        "def train(train_loader, net, epoch):\n",
        "\n",
        "  # Training mode\n",
        "  net.train()\n",
        "  \n",
        "  start = time.time()\n",
        "  \n",
        "  epoch_loss  = []\n",
        "  for batch in train_loader:\n",
        "    \n",
        "    dado, rotulo = batch\n",
        "    \n",
        "    # Cast do dado na GPU\n",
        "    dado = dado.to(args['device'])\n",
        "    rotulo = rotulo.to(args['device'])\n",
        "    \n",
        "    # Forward\n",
        "    ypred = net(dado)\n",
        "    loss = criterion(ypred, rotulo)\n",
        "    epoch_loss.append(loss.cpu().data)\n",
        "    \n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "   \n",
        "  epoch_loss = np.asarray(epoch_loss)\n",
        "  \n",
        "  end = time.time()\n",
        "  print('#################### Train ####################')\n",
        "  print('Epoch %d, Loss: %.4f +/- %.4f, Time: %.2f' % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
        "  \n",
        "  return epoch_loss.mean()\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79KDmwyL4l89"
      },
      "source": [
        "def validate(test_loader, net, epoch):\n",
        "\n",
        "  # Evaluation mode\n",
        "  net.eval()\n",
        "  \n",
        "  start = time.time()\n",
        "  \n",
        "  epoch_loss  = []\n",
        "  \n",
        "  with torch.no_grad(): \n",
        "    for batch in test_loader:\n",
        "\n",
        "      dado, rotulo = batch\n",
        "\n",
        "      # Cast do dado na GPU\n",
        "      dado = dado.to(args['device'])\n",
        "      rotulo = rotulo.to(args['device'])\n",
        "\n",
        "      # Forward\n",
        "      ypred = net(dado)\n",
        "      loss = criterion(ypred, rotulo)\n",
        "      epoch_loss.append(loss.cpu().data)\n",
        "\n",
        "  epoch_loss = np.asarray(epoch_loss)\n",
        "  \n",
        "  end = time.time()\n",
        "  print('********** Validate **********')\n",
        "  print('Epoch %d, Loss: %.4f +/- %.4f, Time: %.2f\\n' % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
        "  \n",
        "  return epoch_loss.mean()\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95dKe7by6Qot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b24f29c-a739-48e9-f75d-27c600156814"
      },
      "source": [
        "train_losses, test_losses = [], []\n",
        "for epoch in range(args['epoch_num']):\n",
        "  \n",
        "  # Train\n",
        "  train_losses.append(train(train_loader, net, epoch))\n",
        "  \n",
        "  # Validate\n",
        "  test_losses.append(validate(test_loader, net, epoch))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "#################### Train ####################\n",
            "Epoch 0, Loss: 164.3091 +/- 41.8290, Time: 2.26\n",
            "********** Validate **********\n",
            "Epoch 0, Loss: 126.1877 +/- 30.5127, Time: 0.42\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 1, Loss: 132.0851 +/- 25.0518, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 1, Loss: 127.3918 +/- 24.2552, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 2, Loss: 123.5236 +/- 29.5951, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 2, Loss: 127.1817 +/- 31.9073, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 3, Loss: 122.3897 +/- 31.0318, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 3, Loss: 116.1245 +/- 26.5783, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 4, Loss: 120.4208 +/- 26.0317, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 4, Loss: 115.0319 +/- 27.3075, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 5, Loss: 119.6440 +/- 29.9864, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 5, Loss: 119.6545 +/- 31.0075, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 6, Loss: 116.5691 +/- 28.1603, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 6, Loss: 120.6641 +/- 27.2274, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 7, Loss: 116.7325 +/- 26.8338, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 7, Loss: 115.6048 +/- 30.1076, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 8, Loss: 114.3825 +/- 29.3999, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 8, Loss: 112.5644 +/- 26.1375, Time: 0.42\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 9, Loss: 111.9032 +/- 26.0059, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 9, Loss: 109.0984 +/- 28.2681, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 10, Loss: 109.0224 +/- 28.1082, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 10, Loss: 106.2193 +/- 25.2054, Time: 0.42\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 11, Loss: 104.9384 +/- 25.4368, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 11, Loss: 102.4691 +/- 26.9372, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 12, Loss: 100.7229 +/- 25.9319, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 12, Loss: 97.9540 +/- 24.2029, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 13, Loss: 97.9217 +/- 24.9878, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 13, Loss: 95.1082 +/- 25.1674, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 14, Loss: 97.1973 +/- 23.3114, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 14, Loss: 95.5566 +/- 25.1408, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 15, Loss: 96.9760 +/- 24.0966, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 15, Loss: 92.0440 +/- 22.5352, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 16, Loss: 95.3641 +/- 23.9844, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 16, Loss: 95.1765 +/- 21.2360, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 17, Loss: 93.6164 +/- 23.9670, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 17, Loss: 89.8993 +/- 21.8870, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 18, Loss: 94.0220 +/- 23.1003, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 18, Loss: 92.5336 +/- 24.7645, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 19, Loss: 92.7365 +/- 21.7887, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 19, Loss: 91.5535 +/- 24.3164, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 20, Loss: 92.6901 +/- 23.0995, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 20, Loss: 87.8659 +/- 21.5784, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 21, Loss: 90.9112 +/- 22.3371, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 21, Loss: 92.2410 +/- 20.9673, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 22, Loss: 90.1398 +/- 23.5646, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 22, Loss: 86.2617 +/- 22.1235, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 23, Loss: 90.6641 +/- 23.5627, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 23, Loss: 91.1756 +/- 25.3884, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 24, Loss: 89.6248 +/- 22.1967, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 24, Loss: 86.0035 +/- 23.1349, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 25, Loss: 89.3129 +/- 24.2834, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 25, Loss: 90.5836 +/- 21.6680, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 26, Loss: 89.2945 +/- 24.3355, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 26, Loss: 85.2874 +/- 23.9010, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 27, Loss: 87.3144 +/- 21.5866, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 27, Loss: 87.4513 +/- 24.8078, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 28, Loss: 87.1704 +/- 22.5488, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 28, Loss: 83.3775 +/- 22.7158, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 29, Loss: 86.3965 +/- 21.8398, Time: 2.23\n",
            "********** Validate **********\n",
            "Epoch 29, Loss: 86.9257 +/- 21.0892, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 30, Loss: 85.5660 +/- 22.0797, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 30, Loss: 86.0546 +/- 20.9529, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 31, Loss: 85.3445 +/- 22.6997, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 31, Loss: 81.7390 +/- 22.7329, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 32, Loss: 84.7906 +/- 22.6902, Time: 2.06\n",
            "********** Validate **********\n",
            "Epoch 32, Loss: 85.9495 +/- 24.7070, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 33, Loss: 84.0130 +/- 21.7108, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 33, Loss: 80.5552 +/- 22.6564, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 34, Loss: 83.3421 +/- 22.4681, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 34, Loss: 83.3850 +/- 20.6776, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 35, Loss: 82.3256 +/- 23.2031, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 35, Loss: 81.1089 +/- 20.9104, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 36, Loss: 82.4814 +/- 22.5841, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 36, Loss: 78.9109 +/- 22.3073, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 37, Loss: 81.6870 +/- 22.1716, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 37, Loss: 80.4594 +/- 23.0031, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 38, Loss: 81.3109 +/- 21.8258, Time: 2.18\n",
            "********** Validate **********\n",
            "Epoch 38, Loss: 82.0725 +/- 23.5493, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 39, Loss: 81.3998 +/- 21.9598, Time: 2.19\n",
            "********** Validate **********\n",
            "Epoch 39, Loss: 79.2138 +/- 22.8038, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 40, Loss: 82.7777 +/- 22.8942, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 40, Loss: 80.0691 +/- 20.2821, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 41, Loss: 80.9142 +/- 23.1471, Time: 2.18\n",
            "********** Validate **********\n",
            "Epoch 41, Loss: 80.6701 +/- 20.1984, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 42, Loss: 80.7818 +/- 22.3526, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 42, Loss: 76.5111 +/- 21.9612, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 43, Loss: 79.9894 +/- 21.2578, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 43, Loss: 81.2611 +/- 23.6783, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 44, Loss: 80.3141 +/- 21.2619, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 44, Loss: 74.9153 +/- 20.9373, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 45, Loss: 79.1916 +/- 22.1352, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 45, Loss: 81.4906 +/- 19.9656, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 46, Loss: 80.0597 +/- 22.4694, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 46, Loss: 74.8963 +/- 22.0140, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 47, Loss: 78.1641 +/- 19.9128, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 47, Loss: 77.7243 +/- 22.8992, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 48, Loss: 78.6773 +/- 21.1828, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 48, Loss: 76.9478 +/- 20.0368, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 49, Loss: 76.2258 +/- 22.3240, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 49, Loss: 73.3567 +/- 19.9486, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 50, Loss: 77.0708 +/- 21.5692, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 50, Loss: 76.6120 +/- 22.6931, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 51, Loss: 75.6569 +/- 21.4549, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 51, Loss: 72.2522 +/- 21.3093, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 52, Loss: 76.8119 +/- 22.6391, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 52, Loss: 79.3846 +/- 19.6904, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 53, Loss: 76.2332 +/- 21.6296, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 53, Loss: 70.9121 +/- 20.9176, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 54, Loss: 74.3751 +/- 19.0402, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 54, Loss: 74.5282 +/- 22.4258, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 55, Loss: 76.8784 +/- 21.5112, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 55, Loss: 80.3847 +/- 19.5079, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 56, Loss: 76.4178 +/- 20.5917, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 56, Loss: 75.4469 +/- 22.6725, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 57, Loss: 74.6739 +/- 20.4099, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 57, Loss: 69.0735 +/- 19.3147, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 58, Loss: 74.3212 +/- 22.8392, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 58, Loss: 67.9664 +/- 19.6179, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 59, Loss: 74.0485 +/- 19.2914, Time: 2.07\n",
            "********** Validate **********\n",
            "Epoch 59, Loss: 72.6740 +/- 22.0993, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 60, Loss: 73.9401 +/- 21.1353, Time: 2.07\n",
            "********** Validate **********\n",
            "Epoch 60, Loss: 75.7501 +/- 18.8502, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 61, Loss: 72.7073 +/- 20.3631, Time: 2.05\n",
            "********** Validate **********\n",
            "Epoch 61, Loss: 73.5997 +/- 22.1887, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 62, Loss: 71.9405 +/- 19.6253, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 62, Loss: 69.7893 +/- 18.8569, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 63, Loss: 70.9116 +/- 20.4036, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 63, Loss: 66.7910 +/- 19.4016, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 64, Loss: 70.0316 +/- 18.7802, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 64, Loss: 68.1894 +/- 20.8534, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 65, Loss: 70.6094 +/- 20.4222, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 65, Loss: 72.3888 +/- 19.2707, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 66, Loss: 69.9692 +/- 18.7628, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 66, Loss: 69.3239 +/- 20.1248, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 67, Loss: 69.2769 +/- 19.0286, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 67, Loss: 65.5653 +/- 19.0582, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 68, Loss: 68.7347 +/- 18.7553, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 68, Loss: 66.4783 +/- 18.6485, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 69, Loss: 68.2271 +/- 18.4733, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 69, Loss: 68.3198 +/- 19.0285, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 70, Loss: 68.1518 +/- 18.3143, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 70, Loss: 67.8913 +/- 19.0416, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 71, Loss: 67.9912 +/- 18.5940, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 71, Loss: 64.5095 +/- 18.4039, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 72, Loss: 67.6219 +/- 19.5957, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 72, Loss: 65.9700 +/- 18.6144, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 73, Loss: 67.6803 +/- 18.8071, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 73, Loss: 68.4171 +/- 19.7430, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 74, Loss: 67.5907 +/- 19.0149, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 74, Loss: 66.0491 +/- 19.1389, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 75, Loss: 66.7801 +/- 18.5395, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 75, Loss: 64.6788 +/- 19.1617, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 76, Loss: 66.9551 +/- 18.5917, Time: 2.18\n",
            "********** Validate **********\n",
            "Epoch 76, Loss: 66.3919 +/- 19.5604, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 77, Loss: 67.2369 +/- 18.1018, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 77, Loss: 65.9989 +/- 18.4021, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 78, Loss: 66.1891 +/- 18.8206, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 78, Loss: 63.6078 +/- 18.5333, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 79, Loss: 65.4410 +/- 19.5640, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 79, Loss: 65.0246 +/- 18.1316, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 80, Loss: 64.9606 +/- 18.8612, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 80, Loss: 64.7657 +/- 17.9704, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 81, Loss: 64.9861 +/- 18.1918, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 81, Loss: 62.3435 +/- 17.5446, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 82, Loss: 64.8769 +/- 17.7482, Time: 2.16\n",
            "********** Validate **********\n",
            "Epoch 82, Loss: 63.8360 +/- 18.3300, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 83, Loss: 64.3199 +/- 18.7855, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 83, Loss: 63.5705 +/- 18.3648, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 84, Loss: 64.2891 +/- 18.3887, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 84, Loss: 61.4311 +/- 17.5355, Time: 0.42\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 85, Loss: 64.1582 +/- 17.9388, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 85, Loss: 62.1058 +/- 18.0587, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 86, Loss: 64.8563 +/- 17.4197, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 86, Loss: 64.2326 +/- 18.0392, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 87, Loss: 64.5868 +/- 17.6658, Time: 2.07\n",
            "********** Validate **********\n",
            "Epoch 87, Loss: 64.9449 +/- 18.1897, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 88, Loss: 64.2625 +/- 17.4858, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 88, Loss: 63.2821 +/- 17.8294, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 89, Loss: 64.0857 +/- 18.0841, Time: 2.07\n",
            "********** Validate **********\n",
            "Epoch 89, Loss: 62.3457 +/- 17.2037, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 90, Loss: 64.4012 +/- 17.7044, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 90, Loss: 61.2246 +/- 17.1563, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 91, Loss: 63.4841 +/- 17.3297, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 91, Loss: 60.7217 +/- 17.0133, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 92, Loss: 63.7178 +/- 17.7088, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 92, Loss: 60.4285 +/- 17.0099, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 93, Loss: 63.4444 +/- 18.3690, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 93, Loss: 59.9766 +/- 16.9199, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 94, Loss: 63.3913 +/- 17.9513, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 94, Loss: 60.4745 +/- 16.9978, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 95, Loss: 62.4196 +/- 18.9229, Time: 2.16\n",
            "********** Validate **********\n",
            "Epoch 95, Loss: 60.0992 +/- 17.2014, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 96, Loss: 61.9801 +/- 16.6346, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 96, Loss: 61.4846 +/- 16.8830, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 97, Loss: 61.7924 +/- 17.2033, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 97, Loss: 61.1394 +/- 16.9240, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 98, Loss: 61.4205 +/- 17.3515, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 98, Loss: 61.9346 +/- 17.4214, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 99, Loss: 61.1326 +/- 16.6034, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 99, Loss: 60.4547 +/- 16.7913, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 100, Loss: 60.6495 +/- 16.8147, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 100, Loss: 59.0886 +/- 16.9104, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 101, Loss: 60.0545 +/- 16.6525, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 101, Loss: 59.1480 +/- 17.0723, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 102, Loss: 60.2420 +/- 16.6150, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 102, Loss: 59.3098 +/- 16.9783, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 103, Loss: 59.3864 +/- 16.1579, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 103, Loss: 58.9592 +/- 16.8559, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 104, Loss: 59.1580 +/- 16.2863, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 104, Loss: 58.4245 +/- 17.3102, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 105, Loss: 59.0588 +/- 16.0189, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 105, Loss: 59.5386 +/- 17.1455, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 106, Loss: 59.4899 +/- 15.8602, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 106, Loss: 58.8206 +/- 17.3318, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 107, Loss: 59.1653 +/- 17.0214, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 107, Loss: 58.2809 +/- 17.3503, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 108, Loss: 59.5926 +/- 15.8173, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 108, Loss: 58.5983 +/- 17.0789, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 109, Loss: 59.5578 +/- 16.1639, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 109, Loss: 59.6927 +/- 17.5354, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 110, Loss: 59.0990 +/- 16.6198, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 110, Loss: 60.9052 +/- 17.4578, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 111, Loss: 59.0963 +/- 15.9468, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 111, Loss: 58.9952 +/- 17.3776, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 112, Loss: 59.0918 +/- 16.1484, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 112, Loss: 58.8607 +/- 16.7006, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 113, Loss: 59.4460 +/- 15.9857, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 113, Loss: 61.4015 +/- 16.7511, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 114, Loss: 59.1010 +/- 17.0834, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 114, Loss: 60.2760 +/- 16.9124, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 115, Loss: 59.7229 +/- 16.0360, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 115, Loss: 57.9796 +/- 16.8572, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 116, Loss: 58.8151 +/- 15.8485, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 116, Loss: 60.1840 +/- 17.4019, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 117, Loss: 59.1944 +/- 16.2880, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 117, Loss: 59.4903 +/- 17.4304, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 118, Loss: 58.4963 +/- 15.9818, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 118, Loss: 59.9616 +/- 16.5924, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 119, Loss: 58.2941 +/- 15.5179, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 119, Loss: 60.6872 +/- 16.9144, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 120, Loss: 57.9269 +/- 16.1310, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 120, Loss: 60.7856 +/- 16.5860, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 121, Loss: 57.8778 +/- 14.8042, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 121, Loss: 59.7596 +/- 16.9406, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 122, Loss: 57.7483 +/- 16.5867, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 122, Loss: 58.0835 +/- 16.2749, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 123, Loss: 57.6692 +/- 17.1303, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 123, Loss: 56.7165 +/- 16.2332, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 124, Loss: 56.9915 +/- 14.7266, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 124, Loss: 56.6822 +/- 16.4505, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 125, Loss: 56.7017 +/- 15.7024, Time: 2.05\n",
            "********** Validate **********\n",
            "Epoch 125, Loss: 58.1487 +/- 16.3806, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 126, Loss: 57.0277 +/- 15.6174, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 126, Loss: 58.9055 +/- 17.1675, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 127, Loss: 56.7743 +/- 15.9153, Time: 2.06\n",
            "********** Validate **********\n",
            "Epoch 127, Loss: 58.0257 +/- 16.2282, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 128, Loss: 56.4984 +/- 15.9168, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 128, Loss: 55.9733 +/- 16.2594, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 129, Loss: 56.4464 +/- 15.5483, Time: 2.07\n",
            "********** Validate **********\n",
            "Epoch 129, Loss: 56.0969 +/- 16.2491, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 130, Loss: 56.1378 +/- 15.6633, Time: 2.07\n",
            "********** Validate **********\n",
            "Epoch 130, Loss: 56.7000 +/- 15.9655, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 131, Loss: 56.5251 +/- 15.1765, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 131, Loss: 57.3739 +/- 16.9604, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 132, Loss: 57.1897 +/- 17.1054, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 132, Loss: 58.0686 +/- 16.2547, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 133, Loss: 57.5595 +/- 16.5930, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 133, Loss: 60.0156 +/- 17.5933, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 134, Loss: 56.7143 +/- 16.0398, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 134, Loss: 57.8471 +/- 16.3491, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 135, Loss: 56.7073 +/- 15.2380, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 135, Loss: 57.6789 +/- 16.5910, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 136, Loss: 56.6961 +/- 14.8622, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 136, Loss: 59.3270 +/- 16.0496, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 137, Loss: 56.1667 +/- 15.9346, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 137, Loss: 57.0157 +/- 16.4115, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 138, Loss: 55.7311 +/- 15.6052, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 138, Loss: 56.8185 +/- 16.1408, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 139, Loss: 55.3371 +/- 15.2159, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 139, Loss: 56.8244 +/- 16.7912, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 140, Loss: 55.5567 +/- 15.7435, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 140, Loss: 57.1257 +/- 16.1403, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 141, Loss: 55.3584 +/- 15.1884, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 141, Loss: 56.2803 +/- 16.7332, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 142, Loss: 54.8931 +/- 14.6595, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 142, Loss: 55.7696 +/- 15.9779, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 143, Loss: 54.8043 +/- 15.9843, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 143, Loss: 54.6616 +/- 16.2139, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 144, Loss: 54.6988 +/- 14.8955, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 144, Loss: 54.8307 +/- 15.8766, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 145, Loss: 54.5344 +/- 15.3084, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 145, Loss: 54.3586 +/- 15.8636, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 146, Loss: 54.4325 +/- 14.7349, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 146, Loss: 54.6990 +/- 15.7524, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 147, Loss: 54.2098 +/- 15.8271, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 147, Loss: 55.2692 +/- 15.4159, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 148, Loss: 53.7393 +/- 15.3105, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 148, Loss: 54.2985 +/- 15.7194, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 149, Loss: 54.1875 +/- 15.2977, Time: 2.18\n",
            "********** Validate **********\n",
            "Epoch 149, Loss: 54.9935 +/- 15.5719, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 150, Loss: 54.8449 +/- 15.1110, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 150, Loss: 57.6712 +/- 15.5943, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 151, Loss: 54.7552 +/- 15.6688, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 151, Loss: 57.1733 +/- 15.6636, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 152, Loss: 54.2554 +/- 15.0270, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 152, Loss: 54.9062 +/- 15.3295, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 153, Loss: 54.6516 +/- 14.2847, Time: 2.07\n",
            "********** Validate **********\n",
            "Epoch 153, Loss: 54.2868 +/- 15.7763, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 154, Loss: 54.4914 +/- 14.8479, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 154, Loss: 56.8603 +/- 16.1687, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 155, Loss: 54.1570 +/- 14.9676, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 155, Loss: 55.1816 +/- 15.9265, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 156, Loss: 55.1793 +/- 15.2027, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 156, Loss: 54.8851 +/- 15.5080, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 157, Loss: 53.9849 +/- 15.4850, Time: 2.05\n",
            "********** Validate **********\n",
            "Epoch 157, Loss: 57.0854 +/- 15.5318, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 158, Loss: 53.9497 +/- 14.4543, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 158, Loss: 54.3056 +/- 15.4261, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 159, Loss: 53.7142 +/- 14.9598, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 159, Loss: 54.6704 +/- 15.3527, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 160, Loss: 53.4743 +/- 14.8857, Time: 2.21\n",
            "********** Validate **********\n",
            "Epoch 160, Loss: 54.5142 +/- 15.4655, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 161, Loss: 53.3100 +/- 16.0859, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 161, Loss: 53.8985 +/- 15.3828, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 162, Loss: 53.4863 +/- 14.7580, Time: 2.17\n",
            "********** Validate **********\n",
            "Epoch 162, Loss: 53.3515 +/- 15.1038, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 163, Loss: 54.0376 +/- 14.7459, Time: 2.16\n",
            "********** Validate **********\n",
            "Epoch 163, Loss: 53.5684 +/- 15.3529, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 164, Loss: 53.2409 +/- 14.3986, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 164, Loss: 54.3191 +/- 15.0951, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 165, Loss: 53.0635 +/- 14.5994, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 165, Loss: 54.8664 +/- 15.9091, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 166, Loss: 53.3796 +/- 14.4427, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 166, Loss: 54.8556 +/- 15.1597, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 167, Loss: 53.2084 +/- 15.2479, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 167, Loss: 53.9990 +/- 15.8118, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 168, Loss: 53.5465 +/- 15.5635, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 168, Loss: 54.6183 +/- 15.1341, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 169, Loss: 53.5108 +/- 15.4016, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 169, Loss: 54.3334 +/- 15.7552, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 170, Loss: 53.0690 +/- 14.6233, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 170, Loss: 54.8211 +/- 14.9917, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 171, Loss: 52.7609 +/- 14.6198, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 171, Loss: 52.9158 +/- 14.8612, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 172, Loss: 52.8848 +/- 15.1355, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 172, Loss: 52.6181 +/- 14.4966, Time: 0.43\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 173, Loss: 53.3263 +/- 15.0997, Time: 2.06\n",
            "********** Validate **********\n",
            "Epoch 173, Loss: 52.9573 +/- 14.5110, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 174, Loss: 53.6433 +/- 15.4782, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 174, Loss: 53.8250 +/- 14.9827, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 175, Loss: 53.2513 +/- 14.7642, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 175, Loss: 56.1979 +/- 15.8750, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 176, Loss: 54.1271 +/- 14.1436, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 176, Loss: 53.6410 +/- 15.2010, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 177, Loss: 54.4834 +/- 15.4187, Time: 2.15\n",
            "********** Validate **********\n",
            "Epoch 177, Loss: 54.8771 +/- 14.8434, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 178, Loss: 53.4360 +/- 14.9005, Time: 2.14\n",
            "********** Validate **********\n",
            "Epoch 178, Loss: 55.0418 +/- 14.9760, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 179, Loss: 53.2367 +/- 14.3776, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 179, Loss: 53.9671 +/- 14.9413, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 180, Loss: 53.7361 +/- 14.7137, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 180, Loss: 55.4453 +/- 15.7993, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 181, Loss: 53.5566 +/- 15.0110, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 181, Loss: 54.3645 +/- 15.4967, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 182, Loss: 54.5168 +/- 14.5916, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 182, Loss: 55.7551 +/- 15.4331, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 183, Loss: 53.1669 +/- 15.3544, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 183, Loss: 54.9167 +/- 14.6968, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 184, Loss: 54.1355 +/- 14.5225, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 184, Loss: 55.7822 +/- 15.6275, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 185, Loss: 53.4389 +/- 14.6169, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 185, Loss: 53.3388 +/- 14.9765, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 186, Loss: 54.1848 +/- 16.2443, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 186, Loss: 56.8109 +/- 14.9742, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 187, Loss: 53.3878 +/- 15.1340, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 187, Loss: 53.6882 +/- 14.8781, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 188, Loss: 53.5082 +/- 14.9223, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 188, Loss: 53.4376 +/- 14.9361, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 189, Loss: 52.4367 +/- 14.0224, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 189, Loss: 53.1460 +/- 15.0942, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 190, Loss: 52.0830 +/- 15.1789, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 190, Loss: 53.1367 +/- 14.9718, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 191, Loss: 51.4888 +/- 14.2941, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 191, Loss: 53.1254 +/- 15.0772, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 192, Loss: 51.4609 +/- 14.3076, Time: 2.08\n",
            "********** Validate **********\n",
            "Epoch 192, Loss: 52.1977 +/- 15.0821, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 193, Loss: 51.1806 +/- 14.9459, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 193, Loss: 52.1061 +/- 14.6782, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 194, Loss: 51.1763 +/- 13.7779, Time: 2.13\n",
            "********** Validate **********\n",
            "Epoch 194, Loss: 52.6466 +/- 14.8985, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 195, Loss: 50.8428 +/- 14.4557, Time: 2.11\n",
            "********** Validate **********\n",
            "Epoch 195, Loss: 52.9601 +/- 14.6749, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 196, Loss: 51.1839 +/- 14.2867, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 196, Loss: 53.5011 +/- 15.0280, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 197, Loss: 51.1536 +/- 13.9623, Time: 2.12\n",
            "********** Validate **********\n",
            "Epoch 197, Loss: 51.8730 +/- 14.8055, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 198, Loss: 51.4870 +/- 14.8845, Time: 2.09\n",
            "********** Validate **********\n",
            "Epoch 198, Loss: 52.0207 +/- 14.9637, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 199, Loss: 51.0031 +/- 13.7668, Time: 2.10\n",
            "********** Validate **********\n",
            "Epoch 199, Loss: 52.0666 +/- 14.9067, Time: 0.44\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqTmpWzUV40g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "079ae325-5093-491a-909e-b0262778314d"
      },
      "source": [
        "Xtest = torch.stack([tup[0] for tup in test_set])\n",
        "Xtest = Xtest.to(args['device'])\n",
        "\n",
        "ytest = torch.stack([tup[1] for tup in test_set])\n",
        "ypred = net(Xtest).cpu().data\n",
        "\n",
        "data = torch.cat((ytest, ypred), axis=1)\n",
        "\n",
        "df_results = pd.DataFrame(data, columns=['ypred', 'ytest'])\n",
        "df_results.head(20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ypred</th>\n",
              "      <th>ytest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tensor(352.)</td>\n",
              "      <td>tensor(303.2035)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tensor(156.)</td>\n",
              "      <td>tensor(139.6221)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tensor(12.)</td>\n",
              "      <td>tensor(7.0859)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tensor(2.)</td>\n",
              "      <td>tensor(0.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tensor(391.)</td>\n",
              "      <td>tensor(367.9622)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tensor(391.)</td>\n",
              "      <td>tensor(285.0840)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tensor(84.)</td>\n",
              "      <td>tensor(153.7791)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tensor(487.)</td>\n",
              "      <td>tensor(589.1534)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tensor(176.)</td>\n",
              "      <td>tensor(206.8352)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tensor(157.)</td>\n",
              "      <td>tensor(71.9581)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>tensor(82.)</td>\n",
              "      <td>tensor(86.2940)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tensor(186.)</td>\n",
              "      <td>tensor(130.7496)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tensor(277.)</td>\n",
              "      <td>tensor(294.4970)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tensor(264.)</td>\n",
              "      <td>tensor(303.3932)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>tensor(312.)</td>\n",
              "      <td>tensor(319.4628)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>tensor(56.)</td>\n",
              "      <td>tensor(36.5844)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tensor(370.)</td>\n",
              "      <td>tensor(163.2502)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>tensor(14.)</td>\n",
              "      <td>tensor(5.5707)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>tensor(124.)</td>\n",
              "      <td>tensor(217.9578)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tensor(427.)</td>\n",
              "      <td>tensor(371.1342)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ypred             ytest\n",
              "0   tensor(352.)  tensor(303.2035)\n",
              "1   tensor(156.)  tensor(139.6221)\n",
              "2    tensor(12.)    tensor(7.0859)\n",
              "3     tensor(2.)        tensor(0.)\n",
              "4   tensor(391.)  tensor(367.9622)\n",
              "5   tensor(391.)  tensor(285.0840)\n",
              "6    tensor(84.)  tensor(153.7791)\n",
              "7   tensor(487.)  tensor(589.1534)\n",
              "8   tensor(176.)  tensor(206.8352)\n",
              "9   tensor(157.)   tensor(71.9581)\n",
              "10   tensor(82.)   tensor(86.2940)\n",
              "11  tensor(186.)  tensor(130.7496)\n",
              "12  tensor(277.)  tensor(294.4970)\n",
              "13  tensor(264.)  tensor(303.3932)\n",
              "14  tensor(312.)  tensor(319.4628)\n",
              "15   tensor(56.)   tensor(36.5844)\n",
              "16  tensor(370.)  tensor(163.2502)\n",
              "17   tensor(14.)    tensor(5.5707)\n",
              "18  tensor(124.)  tensor(217.9578)\n",
              "19  tensor(427.)  tensor(371.1342)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I5L8uae15qz"
      },
      "source": [
        "# Gráfico de convergência"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDM-Iki543ID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "c9d0745a-036a-47c5-ebea-48c40dc0c22c"
      },
      "source": [
        "plt.figure(figsize=(20, 9))\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(test_losses, label='Test', linewidth=3, alpha=0.5)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.title('Convergence', fontsize=16)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}